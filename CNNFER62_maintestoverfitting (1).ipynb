{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPpp_equI2jy",
        "outputId": "5e26f6e3-a1e2-4323-fb3d-f36c09189808"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "   emotion                                             pixels     Usage\n",
            "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
            "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
            "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
            "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
            "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to the CSV file in your Google Drive\n",
        "drive_csv_path = '/content/drive/My Drive/fer2013.csv'\n",
        "\n",
        "weight = '/content/drive/My Drive/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "# Read CSV file into DataFrame\n",
        "data = pd.read_csv(drive_csv_path)\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# Load the FER-2013 dataset\n",
        "# data = pd.read_csv('fer2013.csv')\n",
        "\n",
        "# Extract pixel values and labels\n",
        "pixels = data['pixels'].values\n",
        "labels = data['emotion'].values\n",
        "\n",
        "# Convert pixel values to NumPy arrays\n",
        "images = []\n",
        "for pixel_sequence in pixels:\n",
        "    pixel_list = pixel_sequence.split(' ')\n",
        "    pixel_list = [int(pixel) for pixel in pixel_list]\n",
        "    images.append(np.array(pixel_list).reshape(48, 48))\n",
        "\n",
        "# Convert labels to one-hot encoded format\n",
        "labels = to_categorical(labels, num_classes=7)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(np.array(images), labels, test_size=0.1, random_state=42)\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# Define the CNN model function\n",
        "def create_model(filters_1=32, filters_2=64, filters_3=128, dense_units=128, dropout_rate=0.25, learning_rate=0.001):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(filters_1, (3, 3), activation='relu', input_shape=(48, 48, 1)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Conv2D(filters_2, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Conv2D(filters_3, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(dense_units, activation='relu'))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(7, activation='softmax'))  # 7 emotion classes\n",
        "    model.compile(optimizer=Adam(lr=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Define parameter grid for grid search\n",
        "param_grid = {\n",
        "    'filters_1': [32, 64],\n",
        "    'filters_2': [64, 128],\n",
        "    'filters_3': [128, 256],\n",
        "    'dense_units': [128, 256],\n",
        "    'dropout_rate': [0.25, 0.5],\n",
        "    'learning_rate': [0.001, 0.0001]\n",
        "}\n",
        "\n",
        "# Function to build and train model\n",
        "def build_and_train_model(filters_1, filters_2, filters_3, dense_units, dropout_rate, learning_rate):\n",
        "    model = create_model(filters_1=filters_1, filters_2=filters_2, filters_3=filters_3, dense_units=dense_units, dropout_rate=dropout_rate, learning_rate=learning_rate)\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=64, callbacks=[early_stopping], verbose=0)\n",
        "    return model, history.history['val_accuracy'][-1]\n",
        "\n",
        "# Perform grid search\n",
        "best_accuracy = 0\n",
        "best_params = None\n",
        "for filters_1 in param_grid['filters_1']:\n",
        "    for filters_2 in param_grid['filters_2']:\n",
        "        for filters_3 in param_grid['filters_3']:\n",
        "            for dense_units in param_grid['dense_units']:\n",
        "                for dropout_rate in param_grid['dropout_rate']:\n",
        "                    for learning_rate in param_grid['learning_rate']:\n",
        "                        _, accuracy = build_and_train_model(filters_1, filters_2, filters_3, dense_units, dropout_rate, learning_rate)\n",
        "                        if accuracy > best_accuracy:\n",
        "                            best_accuracy = accuracy\n",
        "                            best_params = {'filters_1': filters_1, 'filters_2': filters_2, 'filters_3': filters_3, 'dense_units': dense_units, 'dropout_rate': dropout_rate, 'learning_rate': learning_rate}\n",
        "\n",
        "# Print the best parameters and best accuracy\n",
        "print(\"Best Parameters: \", best_params)\n",
        "print(\"Best Accuracy: \", best_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOpvE26TXmBI",
        "outputId": "6aa7f520-a77e-421e-e360-a2e326997bec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sZRadYLbkMb",
        "outputId": "7470d6cb-c9a8-45ae-fad4-74a47065f797"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "113/113 [==============================] - 0s 3ms/step - loss: 1.0560 - accuracy: 0.6255\n",
            "Test Accuracy: 0.6255224347114563\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict probabilities for each class\n",
        "y_pred_prob = model.predict(X_test)\n",
        "\n",
        "# Convert probabilities to class labels\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "conf_matrix = confusion_matrix(np.argmax(y_test, axis=1), y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Calculate classification report (including precision, recall, F1-score, and support)\n",
        "class_report = classification_report(np.argmax(y_test, axis=1), y_pred)\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)\n",
        "\n",
        "# Calculate F1 score\n",
        "f1 = f1_score(np.argmax(y_test, axis=1), y_pred, average='weighted')\n",
        "print(\"F1 Score:\", f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aR3u1NDId-rf",
        "outputId": "55723c11-35a2-4895-e75d-ba571e7307ee"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "113/113 [==============================] - 1s 4ms/step\n",
            "Confusion Matrix:\n",
            "[[257   3  38  25  64  19  92]\n",
            " [ 17  23   3   1   3   1   4]\n",
            " [ 54   1 232  18 104  71  65]\n",
            " [ 20   1  20 732  39  21  48]\n",
            " [ 53   1  59  46 293   8 128]\n",
            " [ 13   0  40  28  10 312  11]\n",
            " [ 31   1  28  52  89  14 396]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.52      0.55       498\n",
            "           1       0.77      0.44      0.56        52\n",
            "           2       0.55      0.43      0.48       545\n",
            "           3       0.81      0.83      0.82       881\n",
            "           4       0.49      0.50      0.49       588\n",
            "           5       0.70      0.75      0.73       414\n",
            "           6       0.53      0.65      0.58       611\n",
            "\n",
            "    accuracy                           0.63      3589\n",
            "   macro avg       0.63      0.59      0.60      3589\n",
            "weighted avg       0.63      0.63      0.62      3589\n",
            "\n",
            "F1 Score: 0.6222122355496856\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict probabilities for each class\n",
        "y_pred_prob = model.predict(X_test)\n",
        "\n",
        "# Convert probabilities to class labels\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "conf_matrix = confusion_matrix(np.argmax(y_test, axis=1), y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Calculate classification report (including precision, recall, F1-score, and support)\n",
        "class_report = classification_report(np.argmax(y_test, axis=1), y_pred)\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)\n",
        "\n",
        "# Calculate F1 score\n",
        "f1 = f1_score(np.argmax(y_test, axis=1), y_pred, average='weighted')\n",
        "print(\"F1 Score:\", f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NotQrNZUbsFR",
        "outputId": "d68474ac-2c69-4504-b3d5-a2a5449d5470"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "113/113 [==============================] - 0s 3ms/step\n",
            "Confusion Matrix:\n",
            "[[262   7  24  41  88  11  65]\n",
            " [ 17  21   4   1   8   1   0]\n",
            " [ 72   2 177  37 153  45  59]\n",
            " [ 30   0  10 746  46   7  42]\n",
            " [ 59   1  34  41 352   1 100]\n",
            " [ 11   0  41  40  16 289  17]\n",
            " [ 42   0  27  56 131   7 348]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.53      0.53       498\n",
            "           1       0.68      0.40      0.51        52\n",
            "           2       0.56      0.32      0.41       545\n",
            "           3       0.78      0.85      0.81       881\n",
            "           4       0.44      0.60      0.51       588\n",
            "           5       0.80      0.70      0.75       414\n",
            "           6       0.55      0.57      0.56       611\n",
            "\n",
            "    accuracy                           0.61      3589\n",
            "   macro avg       0.62      0.57      0.58      3589\n",
            "weighted avg       0.62      0.61      0.61      3589\n",
            "\n",
            "F1 Score: 0.60667489976774\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#adding the additional features to the code such as augmentations and early stopping\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Load the FER-2013 dataset\n",
        "# data = pd.read_csv('fer2013.csv')\n",
        "\n",
        "# Extract pixel values and labels\n",
        "pixels = data['pixels'].values\n",
        "labels = data['emotion'].values\n",
        "\n",
        "# Convert pixel values to NumPy arrays\n",
        "images = []\n",
        "for pixel_sequence in pixels:\n",
        "    pixel_list = pixel_sequence.split(' ')\n",
        "    pixel_list = [int(pixel) for pixel in pixel_list]\n",
        "    images.append(np.array(pixel_list).reshape(48, 48))\n",
        "\n",
        "# Convert labels to one-hot encoded format\n",
        "labels = to_categorical(labels, num_classes=7)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(np.array(images), labels, test_size=0.1, random_state=42)\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# Reshape input data to add channel dimension\n",
        "X_train = X_train.reshape(-1, 48, 48, 1)\n",
        "X_test = X_test.reshape(-1, 48, 48, 1)\n",
        "\n",
        "# Data Augmentation\n",
        "datagen = ImageDataGenerator(rotation_range=10, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.1, zoom_range=0.1, horizontal_flip=True)\n",
        "\n",
        "# Create a CNN model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(7, activation='softmax'))  # 7 emotion classes\n",
        "\n",
        "# Compile the model with L2 regularization\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train the model with early stopping and data augmentation\n",
        "history = model.fit(datagen.flow(X_train, y_train, batch_size=64), validation_data=(X_test, y_test), epochs=100, callbacks=[early_stopping])\n",
        "\n",
        "model.save('maintest_overfitting_augmentation.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_JTiCMiYhIz",
        "outputId": "bf1d5342-af18-4327-f390-81890378a46b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "505/505 [==============================] - 19s 33ms/step - loss: 1.8038 - accuracy: 0.2548 - val_loss: 1.7205 - val_accuracy: 0.2967\n",
            "Epoch 2/100\n",
            "505/505 [==============================] - 16s 32ms/step - loss: 1.7172 - accuracy: 0.3047 - val_loss: 1.5803 - val_accuracy: 0.3954\n",
            "Epoch 3/100\n",
            "505/505 [==============================] - 15s 30ms/step - loss: 1.6209 - accuracy: 0.3595 - val_loss: 1.4373 - val_accuracy: 0.4558\n",
            "Epoch 4/100\n",
            "505/505 [==============================] - 15s 30ms/step - loss: 1.5415 - accuracy: 0.4009 - val_loss: 1.3638 - val_accuracy: 0.4932\n",
            "Epoch 5/100\n",
            "505/505 [==============================] - 17s 33ms/step - loss: 1.4790 - accuracy: 0.4298 - val_loss: 1.3102 - val_accuracy: 0.4990\n",
            "Epoch 6/100\n",
            "505/505 [==============================] - 15s 30ms/step - loss: 1.4416 - accuracy: 0.4487 - val_loss: 1.2872 - val_accuracy: 0.5099\n",
            "Epoch 7/100\n",
            "505/505 [==============================] - 16s 31ms/step - loss: 1.4195 - accuracy: 0.4555 - val_loss: 1.2420 - val_accuracy: 0.5258\n",
            "Epoch 8/100\n",
            "505/505 [==============================] - 16s 31ms/step - loss: 1.3993 - accuracy: 0.4646 - val_loss: 1.2206 - val_accuracy: 0.5383\n",
            "Epoch 9/100\n",
            "505/505 [==============================] - 15s 30ms/step - loss: 1.3829 - accuracy: 0.4716 - val_loss: 1.2134 - val_accuracy: 0.5347\n",
            "Epoch 10/100\n",
            "505/505 [==============================] - 15s 30ms/step - loss: 1.3583 - accuracy: 0.4828 - val_loss: 1.1950 - val_accuracy: 0.5461\n",
            "Epoch 11/100\n",
            "505/505 [==============================] - 15s 30ms/step - loss: 1.3580 - accuracy: 0.4836 - val_loss: 1.1862 - val_accuracy: 0.5589\n",
            "Epoch 12/100\n",
            "505/505 [==============================] - 17s 33ms/step - loss: 1.3409 - accuracy: 0.4892 - val_loss: 1.1757 - val_accuracy: 0.5623\n",
            "Epoch 13/100\n",
            "505/505 [==============================] - 15s 30ms/step - loss: 1.3373 - accuracy: 0.4904 - val_loss: 1.1624 - val_accuracy: 0.5634\n",
            "Epoch 14/100\n",
            "505/505 [==============================] - 15s 30ms/step - loss: 1.3273 - accuracy: 0.4948 - val_loss: 1.1511 - val_accuracy: 0.5667\n",
            "Epoch 15/100\n",
            "505/505 [==============================] - 17s 33ms/step - loss: 1.3262 - accuracy: 0.4942 - val_loss: 1.1579 - val_accuracy: 0.5592\n",
            "Epoch 16/100\n",
            "505/505 [==============================] - 15s 31ms/step - loss: 1.3122 - accuracy: 0.5028 - val_loss: 1.1500 - val_accuracy: 0.5704\n",
            "Epoch 17/100\n",
            "505/505 [==============================] - 15s 30ms/step - loss: 1.3051 - accuracy: 0.5040 - val_loss: 1.1312 - val_accuracy: 0.5765\n",
            "Epoch 18/100\n",
            "505/505 [==============================] - 15s 30ms/step - loss: 1.3020 - accuracy: 0.5044 - val_loss: 1.1495 - val_accuracy: 0.5687\n",
            "Epoch 19/100\n",
            "505/505 [==============================] - 31s 62ms/step - loss: 1.2987 - accuracy: 0.5068 - val_loss: 1.1337 - val_accuracy: 0.5784\n",
            "Epoch 20/100\n",
            "505/505 [==============================] - 19s 38ms/step - loss: 1.2920 - accuracy: 0.5115 - val_loss: 1.1152 - val_accuracy: 0.5812\n",
            "Epoch 21/100\n",
            "505/505 [==============================] - 15s 30ms/step - loss: 1.2845 - accuracy: 0.5163 - val_loss: 1.1174 - val_accuracy: 0.5765\n",
            "Epoch 22/100\n",
            "505/505 [==============================] - 16s 31ms/step - loss: 1.2820 - accuracy: 0.5124 - val_loss: 1.1215 - val_accuracy: 0.5798\n",
            "Epoch 23/100\n",
            "505/505 [==============================] - 15s 30ms/step - loss: 1.2768 - accuracy: 0.5146 - val_loss: 1.1170 - val_accuracy: 0.5731\n",
            "Epoch 24/100\n",
            "505/505 [==============================] - 15s 30ms/step - loss: 1.2700 - accuracy: 0.5163 - val_loss: 1.1032 - val_accuracy: 0.5784\n",
            "Epoch 25/100\n",
            "505/505 [==============================] - 16s 31ms/step - loss: 1.2689 - accuracy: 0.5183 - val_loss: 1.1141 - val_accuracy: 0.5745\n",
            "Epoch 26/100\n",
            "505/505 [==============================] - 17s 34ms/step - loss: 1.2642 - accuracy: 0.5191 - val_loss: 1.1047 - val_accuracy: 0.5834\n",
            "Epoch 27/100\n",
            "505/505 [==============================] - 15s 30ms/step - loss: 1.2588 - accuracy: 0.5246 - val_loss: 1.0910 - val_accuracy: 0.5885\n",
            "Epoch 28/100\n",
            "505/505 [==============================] - 15s 30ms/step - loss: 1.2683 - accuracy: 0.5199 - val_loss: 1.1023 - val_accuracy: 0.5823\n",
            "Epoch 29/100\n",
            "505/505 [==============================] - 15s 31ms/step - loss: 1.2559 - accuracy: 0.5286 - val_loss: 1.0932 - val_accuracy: 0.5823\n",
            "Epoch 30/100\n",
            "505/505 [==============================] - 16s 31ms/step - loss: 1.2552 - accuracy: 0.5241 - val_loss: 1.0825 - val_accuracy: 0.5915\n",
            "Epoch 31/100\n",
            "505/505 [==============================] - 16s 32ms/step - loss: 1.2553 - accuracy: 0.5247 - val_loss: 1.0878 - val_accuracy: 0.5874\n",
            "Epoch 32/100\n",
            "505/505 [==============================] - 15s 30ms/step - loss: 1.2470 - accuracy: 0.5288 - val_loss: 1.0893 - val_accuracy: 0.5899\n",
            "Epoch 33/100\n",
            "505/505 [==============================] - 15s 30ms/step - loss: 1.2506 - accuracy: 0.5258 - val_loss: 1.0664 - val_accuracy: 0.6024\n",
            "Epoch 34/100\n",
            "505/505 [==============================] - 16s 31ms/step - loss: 1.2475 - accuracy: 0.5267 - val_loss: 1.0860 - val_accuracy: 0.5913\n",
            "Epoch 35/100\n",
            "505/505 [==============================] - 15s 30ms/step - loss: 1.2416 - accuracy: 0.5302 - val_loss: 1.0741 - val_accuracy: 0.5965\n",
            "Epoch 36/100\n",
            "505/505 [==============================] - 15s 30ms/step - loss: 1.2404 - accuracy: 0.5271 - val_loss: 1.0713 - val_accuracy: 0.5935\n",
            "Epoch 37/100\n",
            "505/505 [==============================] - 15s 30ms/step - loss: 1.2342 - accuracy: 0.5350 - val_loss: 1.0711 - val_accuracy: 0.5982\n",
            "Epoch 38/100\n",
            "505/505 [==============================] - 17s 34ms/step - loss: 1.2419 - accuracy: 0.5294 - val_loss: 1.0671 - val_accuracy: 0.5949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.applications import VGG16\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Flatten, Dropout\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# # Load the FER-2013 dataset\n",
        "# data = pd.read_csv('fer2013.csv')\n",
        "\n",
        "# Extract pixel values and labels\n",
        "pixels = data['pixels'].values\n",
        "labels = data['emotion'].values\n",
        "\n",
        "# Convert pixel values to NumPy arrays\n",
        "images = []\n",
        "for pixel_sequence in pixels:\n",
        "    pixel_list = pixel_sequence.split(' ')\n",
        "    pixel_list = [int(pixel) for pixel in pixel_list]\n",
        "    images.append(np.array(pixel_list).reshape(48, 48))\n",
        "\n",
        "# Convert labels to one-hot encoded format\n",
        "labels = to_categorical(labels, num_classes=7)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(np.array(images), labels, test_size=0.1, random_state=42)\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# Convert grayscale images to RGB format\n",
        "X_train_rgb = np.repeat(X_train[..., np.newaxis], 3, -1)\n",
        "X_test_rgb = np.repeat(X_test[..., np.newaxis], 3, -1)\n",
        "\n",
        "\n",
        "\n",
        "# Load pre-trained VGG16 model without the top layers\n",
        "base_model = VGG16(weights=weight, include_top=False, input_shape=(48, 48, 3))\n",
        "\n",
        "# Freeze the pre-trained layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add new classification layers\n",
        "x = Flatten()(base_model.output)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(7, activation='softmax')(x)\n",
        "\n",
        "# Create the final model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_rgb, y_train, validation_data=(X_test_rgb, y_test), epochs=20, batch_size=64)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test_rgb, y_test)\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "\n",
        "# Save the model\n",
        "model.save('vgg16_fer2013.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JCcUgpsJeDu",
        "outputId": "b7a9d61e-d00e-4068-919e-4801f9323188"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "505/505 [==============================] - 19s 27ms/step - loss: 1.8109 - accuracy: 0.2683 - val_loss: 1.6650 - val_accuracy: 0.3441\n",
            "Epoch 2/20\n",
            "505/505 [==============================] - 12s 23ms/step - loss: 1.6832 - accuracy: 0.3320 - val_loss: 1.6298 - val_accuracy: 0.3561\n",
            "Epoch 3/20\n",
            "505/505 [==============================] - 12s 23ms/step - loss: 1.6435 - accuracy: 0.3551 - val_loss: 1.6057 - val_accuracy: 0.3728\n",
            "Epoch 4/20\n",
            "505/505 [==============================] - 12s 23ms/step - loss: 1.6180 - accuracy: 0.3683 - val_loss: 1.5906 - val_accuracy: 0.3842\n",
            "Epoch 5/20\n",
            "505/505 [==============================] - 11s 21ms/step - loss: 1.6012 - accuracy: 0.3774 - val_loss: 1.5801 - val_accuracy: 0.3837\n",
            "Epoch 6/20\n",
            "505/505 [==============================] - 11s 22ms/step - loss: 1.5858 - accuracy: 0.3838 - val_loss: 1.5678 - val_accuracy: 0.3912\n",
            "Epoch 7/20\n",
            "505/505 [==============================] - 11s 22ms/step - loss: 1.5714 - accuracy: 0.3901 - val_loss: 1.5596 - val_accuracy: 0.3996\n",
            "Epoch 8/20\n",
            "505/505 [==============================] - 11s 22ms/step - loss: 1.5616 - accuracy: 0.3976 - val_loss: 1.5516 - val_accuracy: 0.4023\n",
            "Epoch 9/20\n",
            "505/505 [==============================] - 11s 22ms/step - loss: 1.5510 - accuracy: 0.4036 - val_loss: 1.5458 - val_accuracy: 0.4012\n",
            "Epoch 10/20\n",
            "505/505 [==============================] - 11s 22ms/step - loss: 1.5439 - accuracy: 0.4057 - val_loss: 1.5417 - val_accuracy: 0.4018\n",
            "Epoch 11/20\n",
            "505/505 [==============================] - 11s 22ms/step - loss: 1.5316 - accuracy: 0.4084 - val_loss: 1.5378 - val_accuracy: 0.4068\n",
            "Epoch 12/20\n",
            "505/505 [==============================] - 12s 23ms/step - loss: 1.5252 - accuracy: 0.4149 - val_loss: 1.5305 - val_accuracy: 0.4051\n",
            "Epoch 13/20\n",
            "505/505 [==============================] - 11s 22ms/step - loss: 1.5189 - accuracy: 0.4163 - val_loss: 1.5293 - val_accuracy: 0.4046\n",
            "Epoch 14/20\n",
            "505/505 [==============================] - 11s 22ms/step - loss: 1.5105 - accuracy: 0.4213 - val_loss: 1.5253 - val_accuracy: 0.4101\n",
            "Epoch 15/20\n",
            "505/505 [==============================] - 11s 22ms/step - loss: 1.5076 - accuracy: 0.4217 - val_loss: 1.5187 - val_accuracy: 0.4146\n",
            "Epoch 16/20\n",
            "505/505 [==============================] - 11s 22ms/step - loss: 1.4997 - accuracy: 0.4251 - val_loss: 1.5172 - val_accuracy: 0.4132\n",
            "Epoch 17/20\n",
            "505/505 [==============================] - 11s 22ms/step - loss: 1.4925 - accuracy: 0.4296 - val_loss: 1.5131 - val_accuracy: 0.4160\n",
            "Epoch 18/20\n",
            "505/505 [==============================] - 11s 22ms/step - loss: 1.4845 - accuracy: 0.4299 - val_loss: 1.5101 - val_accuracy: 0.4179\n",
            "Epoch 19/20\n",
            "505/505 [==============================] - 11s 22ms/step - loss: 1.4848 - accuracy: 0.4321 - val_loss: 1.5084 - val_accuracy: 0.4179\n",
            "Epoch 20/20\n",
            "505/505 [==============================] - 11s 22ms/step - loss: 1.4785 - accuracy: 0.4332 - val_loss: 1.5071 - val_accuracy: 0.4149\n",
            "113/113 [==============================] - 2s 12ms/step - loss: 1.5071 - accuracy: 0.4149\n",
            "Test Accuracy: 0.414878785610199\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the FER-2013 dataset\n",
        "# data = pd.read_csv('fer2013.csv')\n",
        "\n",
        "# Extract pixel values and labels\n",
        "pixels = data['pixels'].values\n",
        "labels = data['emotion'].values\n",
        "\n",
        "# Convert pixel values to NumPy arrays\n",
        "images = []\n",
        "for pixel_sequence in pixels:\n",
        "    pixel_list = pixel_sequence.split(' ')\n",
        "    pixel_list = [int(pixel) for pixel in pixel_list]\n",
        "    images.append(np.array(pixel_list).reshape(48, 48))\n",
        "\n",
        "# Convert labels to one-hot encoded format\n",
        "labels = to_categorical(labels, num_classes=7)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(np.array(images), labels, test_size=0.1, random_state=42)\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# Create a CNN model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(7, activation='softmax'))  # 7 emotion classes\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=64)\n",
        "\n",
        "model.save('maintest.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbeTNQS8J6kS",
        "outputId": "60a6bcb2-b18b-445c-d0e4-3015e8577589"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "505/505 [==============================] - 7s 9ms/step - loss: 1.7208 - accuracy: 0.3062 - val_loss: 1.5209 - val_accuracy: 0.4157\n",
            "Epoch 2/20\n",
            "505/505 [==============================] - 3s 7ms/step - loss: 1.4643 - accuracy: 0.4355 - val_loss: 1.3538 - val_accuracy: 0.4870\n",
            "Epoch 3/20\n",
            "505/505 [==============================] - 3s 7ms/step - loss: 1.3564 - accuracy: 0.4808 - val_loss: 1.3040 - val_accuracy: 0.5057\n",
            "Epoch 4/20\n",
            "505/505 [==============================] - 4s 7ms/step - loss: 1.2853 - accuracy: 0.5114 - val_loss: 1.2479 - val_accuracy: 0.5283\n",
            "Epoch 5/20\n",
            "505/505 [==============================] - 4s 8ms/step - loss: 1.2285 - accuracy: 0.5333 - val_loss: 1.2344 - val_accuracy: 0.5208\n",
            "Epoch 6/20\n",
            "505/505 [==============================] - 3s 7ms/step - loss: 1.1891 - accuracy: 0.5526 - val_loss: 1.2003 - val_accuracy: 0.5461\n",
            "Epoch 7/20\n",
            "505/505 [==============================] - 3s 6ms/step - loss: 1.1447 - accuracy: 0.5644 - val_loss: 1.1670 - val_accuracy: 0.5545\n",
            "Epoch 8/20\n",
            "505/505 [==============================] - 4s 7ms/step - loss: 1.1064 - accuracy: 0.5803 - val_loss: 1.1677 - val_accuracy: 0.5617\n",
            "Epoch 9/20\n",
            "505/505 [==============================] - 4s 7ms/step - loss: 1.0773 - accuracy: 0.5931 - val_loss: 1.1690 - val_accuracy: 0.5623\n",
            "Epoch 10/20\n",
            "505/505 [==============================] - 3s 6ms/step - loss: 1.0481 - accuracy: 0.6025 - val_loss: 1.1543 - val_accuracy: 0.5715\n",
            "Epoch 11/20\n",
            "505/505 [==============================] - 3s 7ms/step - loss: 1.0171 - accuracy: 0.6138 - val_loss: 1.1576 - val_accuracy: 0.5662\n",
            "Epoch 12/20\n",
            "505/505 [==============================] - 4s 8ms/step - loss: 0.9855 - accuracy: 0.6247 - val_loss: 1.1579 - val_accuracy: 0.5748\n",
            "Epoch 13/20\n",
            "505/505 [==============================] - 3s 7ms/step - loss: 0.9582 - accuracy: 0.6353 - val_loss: 1.2165 - val_accuracy: 0.5681\n",
            "Epoch 14/20\n",
            "505/505 [==============================] - 3s 7ms/step - loss: 0.9340 - accuracy: 0.6428 - val_loss: 1.1823 - val_accuracy: 0.5737\n",
            "Epoch 15/20\n",
            "505/505 [==============================] - 3s 7ms/step - loss: 0.9049 - accuracy: 0.6551 - val_loss: 1.1970 - val_accuracy: 0.5684\n",
            "Epoch 16/20\n",
            "505/505 [==============================] - 4s 7ms/step - loss: 0.8803 - accuracy: 0.6610 - val_loss: 1.2033 - val_accuracy: 0.5737\n",
            "Epoch 17/20\n",
            "505/505 [==============================] - 3s 6ms/step - loss: 0.8539 - accuracy: 0.6703 - val_loss: 1.2412 - val_accuracy: 0.5698\n",
            "Epoch 18/20\n",
            "505/505 [==============================] - 3s 7ms/step - loss: 0.8280 - accuracy: 0.6811 - val_loss: 1.2769 - val_accuracy: 0.5678\n",
            "Epoch 19/20\n",
            "505/505 [==============================] - 5s 9ms/step - loss: 0.8043 - accuracy: 0.6888 - val_loss: 1.2496 - val_accuracy: 0.5648\n",
            "Epoch 20/20\n",
            "505/505 [==============================] - 3s 7ms/step - loss: 0.7802 - accuracy: 0.6970 - val_loss: 1.3045 - val_accuracy: 0.5759\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# Create a CNN model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), activation='relu'))  # Additional Convolutional layer\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256, activation='relu'))  # Additional Dense layer\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(128, activation='relu'))  # Additional Dense layer\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(7, activation='softmax'))  # 7 emotion classes\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=64)\n",
        "\n",
        "model.save('improved_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CI25ST9Lo9u",
        "outputId": "782cebc9-e74c-49df-cd1e-f750c65db416"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "505/505 [==============================] - 7s 9ms/step - loss: 1.8253 - accuracy: 0.2444 - val_loss: 1.7875 - val_accuracy: 0.2452\n",
            "Epoch 2/20\n",
            "505/505 [==============================] - 4s 8ms/step - loss: 1.6217 - accuracy: 0.3494 - val_loss: 1.4310 - val_accuracy: 0.4444\n",
            "Epoch 3/20\n",
            "505/505 [==============================] - 4s 8ms/step - loss: 1.4079 - accuracy: 0.4598 - val_loss: 1.3181 - val_accuracy: 0.4901\n",
            "Epoch 4/20\n",
            "505/505 [==============================] - 4s 8ms/step - loss: 1.3102 - accuracy: 0.4997 - val_loss: 1.2650 - val_accuracy: 0.5138\n",
            "Epoch 5/20\n",
            "505/505 [==============================] - 4s 8ms/step - loss: 1.2390 - accuracy: 0.5302 - val_loss: 1.2121 - val_accuracy: 0.5361\n",
            "Epoch 6/20\n",
            "505/505 [==============================] - 4s 8ms/step - loss: 1.1780 - accuracy: 0.5556 - val_loss: 1.2218 - val_accuracy: 0.5372\n",
            "Epoch 7/20\n",
            "505/505 [==============================] - 4s 7ms/step - loss: 1.1374 - accuracy: 0.5728 - val_loss: 1.2052 - val_accuracy: 0.5472\n",
            "Epoch 8/20\n",
            "505/505 [==============================] - 4s 9ms/step - loss: 1.0823 - accuracy: 0.5963 - val_loss: 1.2052 - val_accuracy: 0.5436\n",
            "Epoch 9/20\n",
            "505/505 [==============================] - 4s 7ms/step - loss: 1.0415 - accuracy: 0.6111 - val_loss: 1.2016 - val_accuracy: 0.5570\n",
            "Epoch 10/20\n",
            "505/505 [==============================] - 4s 8ms/step - loss: 0.9963 - accuracy: 0.6231 - val_loss: 1.2168 - val_accuracy: 0.5548\n",
            "Epoch 11/20\n",
            "505/505 [==============================] - 4s 9ms/step - loss: 0.9547 - accuracy: 0.6405 - val_loss: 1.2442 - val_accuracy: 0.5614\n",
            "Epoch 12/20\n",
            "505/505 [==============================] - 4s 8ms/step - loss: 0.9134 - accuracy: 0.6595 - val_loss: 1.2396 - val_accuracy: 0.5665\n",
            "Epoch 13/20\n",
            "505/505 [==============================] - 4s 7ms/step - loss: 0.8680 - accuracy: 0.6746 - val_loss: 1.2691 - val_accuracy: 0.5539\n",
            "Epoch 14/20\n",
            "505/505 [==============================] - 4s 8ms/step - loss: 0.8247 - accuracy: 0.6914 - val_loss: 1.3192 - val_accuracy: 0.5545\n",
            "Epoch 15/20\n",
            "505/505 [==============================] - 4s 8ms/step - loss: 0.7867 - accuracy: 0.7064 - val_loss: 1.4282 - val_accuracy: 0.5614\n",
            "Epoch 16/20\n",
            "505/505 [==============================] - 4s 7ms/step - loss: 0.7545 - accuracy: 0.7210 - val_loss: 1.3801 - val_accuracy: 0.5575\n",
            "Epoch 17/20\n",
            "505/505 [==============================] - 4s 8ms/step - loss: 0.7141 - accuracy: 0.7331 - val_loss: 1.4761 - val_accuracy: 0.5648\n",
            "Epoch 18/20\n",
            "505/505 [==============================] - 4s 9ms/step - loss: 0.6878 - accuracy: 0.7449 - val_loss: 1.4867 - val_accuracy: 0.5553\n",
            "Epoch 19/20\n",
            "505/505 [==============================] - 4s 8ms/step - loss: 0.6433 - accuracy: 0.7641 - val_loss: 1.5555 - val_accuracy: 0.5559\n",
            "Epoch 20/20\n",
            "505/505 [==============================] - 4s 8ms/step - loss: 0.6179 - accuracy: 0.7731 - val_loss: 1.6736 - val_accuracy: 0.5517\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "\n",
        "# Load the FER-2013 dataset\n",
        "# data = pd.read_csv('fer2013.csv')\n",
        "\n",
        "# Extract pixel values and labels\n",
        "pixels = data['pixels'].values\n",
        "labels = data['emotion'].values\n",
        "\n",
        "# Convert pixel values to NumPy arrays\n",
        "images = []\n",
        "for pixel_sequence in pixels:\n",
        "    pixel_list = pixel_sequence.split(' ')\n",
        "    pixel_list = [int(pixel) for pixel in pixel_list]\n",
        "    images.append(np.array(pixel_list).reshape(48, 48))\n",
        "\n",
        "# Convert labels to one-hot encoded format\n",
        "labels = to_categorical(labels, num_classes=7)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(np.array(images), labels, test_size=0.1, random_state=42)\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# Reshape input data to include the channel dimension\n",
        "X_train = X_train.reshape(-1, 48, 48, 1)\n",
        "X_test = X_test.reshape(-1, 48, 48, 1)\n",
        "\n",
        "# Data Augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Learning Rate Scheduler\n",
        "def lr_schedule(epoch):\n",
        "    lr = 1e-3\n",
        "    if epoch > 20:\n",
        "        lr *= 0.5\n",
        "    elif epoch > 40:\n",
        "        lr *= 0.2\n",
        "    return lr\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "# Create a CNN model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(7, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with data augmentation and learning rate scheduling\n",
        "model.fit(datagen.flow(X_train, y_train, batch_size=64),\n",
        "          steps_per_epoch=len(X_train) / 64,\n",
        "          epochs=60,\n",
        "          validation_data=(X_test, y_test),\n",
        "          callbacks=[lr_scheduler])\n",
        "\n",
        "# Save the trained model\n",
        "model.save('improved_model_with_augmentation.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRq1ihHjPk8L",
        "outputId": "392f8ed1-3f67-4f26-933c-04154258656d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "504/504 [==============================] - 20s 34ms/step - loss: 1.8216 - accuracy: 0.2460 - val_loss: 1.8015 - val_accuracy: 0.2455 - lr: 0.0010\n",
            "Epoch 2/60\n",
            "504/504 [==============================] - 17s 34ms/step - loss: 1.7921 - accuracy: 0.2548 - val_loss: 1.7212 - val_accuracy: 0.2797 - lr: 0.0010\n",
            "Epoch 3/60\n",
            "504/504 [==============================] - 19s 39ms/step - loss: 1.7484 - accuracy: 0.2801 - val_loss: 1.6764 - val_accuracy: 0.3104 - lr: 0.0010\n",
            "Epoch 4/60\n",
            "504/504 [==============================] - 18s 37ms/step - loss: 1.6876 - accuracy: 0.3137 - val_loss: 1.5460 - val_accuracy: 0.4007 - lr: 0.0010\n",
            "Epoch 5/60\n",
            "504/504 [==============================] - 18s 35ms/step - loss: 1.5795 - accuracy: 0.3783 - val_loss: 1.3621 - val_accuracy: 0.4728 - lr: 0.0010\n",
            "Epoch 6/60\n",
            "504/504 [==============================] - 17s 34ms/step - loss: 1.5039 - accuracy: 0.4154 - val_loss: 1.3564 - val_accuracy: 0.4831 - lr: 0.0010\n",
            "Epoch 7/60\n",
            "504/504 [==============================] - 18s 37ms/step - loss: 1.4596 - accuracy: 0.4368 - val_loss: 1.2994 - val_accuracy: 0.4965 - lr: 0.0010\n",
            "Epoch 8/60\n",
            "504/504 [==============================] - 17s 34ms/step - loss: 1.4292 - accuracy: 0.4488 - val_loss: 1.2746 - val_accuracy: 0.5118 - lr: 0.0010\n",
            "Epoch 9/60\n",
            "504/504 [==============================] - 17s 33ms/step - loss: 1.4107 - accuracy: 0.4583 - val_loss: 1.2408 - val_accuracy: 0.5224 - lr: 0.0010\n",
            "Epoch 10/60\n",
            "504/504 [==============================] - 17s 34ms/step - loss: 1.3920 - accuracy: 0.4654 - val_loss: 1.2390 - val_accuracy: 0.5302 - lr: 0.0010\n",
            "Epoch 11/60\n",
            "504/504 [==============================] - 17s 33ms/step - loss: 1.3878 - accuracy: 0.4699 - val_loss: 1.2218 - val_accuracy: 0.5403 - lr: 0.0010\n",
            "Epoch 12/60\n",
            "504/504 [==============================] - 17s 34ms/step - loss: 1.3743 - accuracy: 0.4738 - val_loss: 1.2081 - val_accuracy: 0.5366 - lr: 0.0010\n",
            "Epoch 13/60\n",
            "504/504 [==============================] - 17s 33ms/step - loss: 1.3595 - accuracy: 0.4824 - val_loss: 1.2364 - val_accuracy: 0.5311 - lr: 0.0010\n",
            "Epoch 14/60\n",
            "504/504 [==============================] - 18s 36ms/step - loss: 1.3495 - accuracy: 0.4854 - val_loss: 1.2029 - val_accuracy: 0.5389 - lr: 0.0010\n",
            "Epoch 15/60\n",
            "504/504 [==============================] - 17s 34ms/step - loss: 1.3400 - accuracy: 0.4878 - val_loss: 1.1647 - val_accuracy: 0.5623 - lr: 0.0010\n",
            "Epoch 16/60\n",
            "504/504 [==============================] - 18s 36ms/step - loss: 1.3311 - accuracy: 0.4907 - val_loss: 1.1823 - val_accuracy: 0.5506 - lr: 0.0010\n",
            "Epoch 17/60\n",
            "504/504 [==============================] - 17s 33ms/step - loss: 1.3208 - accuracy: 0.4964 - val_loss: 1.1718 - val_accuracy: 0.5536 - lr: 0.0010\n",
            "Epoch 18/60\n",
            "504/504 [==============================] - 18s 35ms/step - loss: 1.3216 - accuracy: 0.4969 - val_loss: 1.1624 - val_accuracy: 0.5617 - lr: 0.0010\n",
            "Epoch 19/60\n",
            "504/504 [==============================] - 17s 34ms/step - loss: 1.3146 - accuracy: 0.5009 - val_loss: 1.1533 - val_accuracy: 0.5587 - lr: 0.0010\n",
            "Epoch 20/60\n",
            "504/504 [==============================] - 17s 34ms/step - loss: 1.3098 - accuracy: 0.5020 - val_loss: 1.1428 - val_accuracy: 0.5701 - lr: 0.0010\n",
            "Epoch 21/60\n",
            "504/504 [==============================] - 17s 34ms/step - loss: 1.2976 - accuracy: 0.5100 - val_loss: 1.1652 - val_accuracy: 0.5548 - lr: 0.0010\n",
            "Epoch 22/60\n",
            "504/504 [==============================] - 17s 33ms/step - loss: 1.2697 - accuracy: 0.5202 - val_loss: 1.1295 - val_accuracy: 0.5662 - lr: 5.0000e-04\n",
            "Epoch 23/60\n",
            "504/504 [==============================] - 18s 36ms/step - loss: 1.2659 - accuracy: 0.5233 - val_loss: 1.1124 - val_accuracy: 0.5743 - lr: 5.0000e-04\n",
            "Epoch 24/60\n",
            "504/504 [==============================] - 17s 34ms/step - loss: 1.2551 - accuracy: 0.5250 - val_loss: 1.1132 - val_accuracy: 0.5748 - lr: 5.0000e-04\n",
            "Epoch 25/60\n",
            "504/504 [==============================] - 17s 35ms/step - loss: 1.2562 - accuracy: 0.5242 - val_loss: 1.1353 - val_accuracy: 0.5709 - lr: 5.0000e-04\n",
            "Epoch 26/60\n",
            "504/504 [==============================] - 17s 33ms/step - loss: 1.2516 - accuracy: 0.5267 - val_loss: 1.0977 - val_accuracy: 0.5784 - lr: 5.0000e-04\n",
            "Epoch 27/60\n",
            "504/504 [==============================] - 17s 34ms/step - loss: 1.2510 - accuracy: 0.5305 - val_loss: 1.1140 - val_accuracy: 0.5829 - lr: 5.0000e-04\n",
            "Epoch 28/60\n",
            "504/504 [==============================] - 17s 33ms/step - loss: 1.2389 - accuracy: 0.5325 - val_loss: 1.0885 - val_accuracy: 0.5896 - lr: 5.0000e-04\n",
            "Epoch 29/60\n",
            "504/504 [==============================] - 18s 36ms/step - loss: 1.2443 - accuracy: 0.5296 - val_loss: 1.1044 - val_accuracy: 0.5740 - lr: 5.0000e-04\n",
            "Epoch 30/60\n",
            "504/504 [==============================] - 17s 34ms/step - loss: 1.2375 - accuracy: 0.5328 - val_loss: 1.0826 - val_accuracy: 0.5926 - lr: 5.0000e-04\n",
            "Epoch 31/60\n",
            "504/504 [==============================] - 18s 37ms/step - loss: 1.2332 - accuracy: 0.5349 - val_loss: 1.0831 - val_accuracy: 0.5910 - lr: 5.0000e-04\n",
            "Epoch 32/60\n",
            "504/504 [==============================] - 17s 33ms/step - loss: 1.2363 - accuracy: 0.5343 - val_loss: 1.0845 - val_accuracy: 0.5876 - lr: 5.0000e-04\n",
            "Epoch 33/60\n",
            "504/504 [==============================] - 17s 34ms/step - loss: 1.2309 - accuracy: 0.5379 - val_loss: 1.0829 - val_accuracy: 0.5926 - lr: 5.0000e-04\n",
            "Epoch 34/60\n",
            "504/504 [==============================] - 17s 33ms/step - loss: 1.2207 - accuracy: 0.5416 - val_loss: 1.1009 - val_accuracy: 0.5840 - lr: 5.0000e-04\n",
            "Epoch 35/60\n",
            "504/504 [==============================] - 18s 36ms/step - loss: 1.2259 - accuracy: 0.5383 - val_loss: 1.0861 - val_accuracy: 0.5882 - lr: 5.0000e-04\n",
            "Epoch 36/60\n",
            "504/504 [==============================] - 17s 34ms/step - loss: 1.2264 - accuracy: 0.5377 - val_loss: 1.0834 - val_accuracy: 0.5882 - lr: 5.0000e-04\n",
            "Epoch 37/60\n",
            "504/504 [==============================] - 18s 35ms/step - loss: 1.2237 - accuracy: 0.5384 - val_loss: 1.0670 - val_accuracy: 0.5940 - lr: 5.0000e-04\n",
            "Epoch 38/60\n",
            "504/504 [==============================] - 17s 33ms/step - loss: 1.2155 - accuracy: 0.5426 - val_loss: 1.0872 - val_accuracy: 0.5829 - lr: 5.0000e-04\n",
            "Epoch 39/60\n",
            "504/504 [==============================] - 17s 33ms/step - loss: 1.2104 - accuracy: 0.5406 - val_loss: 1.0990 - val_accuracy: 0.5737 - lr: 5.0000e-04\n",
            "Epoch 40/60\n",
            "504/504 [==============================] - 17s 33ms/step - loss: 1.2062 - accuracy: 0.5456 - val_loss: 1.0663 - val_accuracy: 0.5893 - lr: 5.0000e-04\n",
            "Epoch 41/60\n",
            "504/504 [==============================] - 17s 34ms/step - loss: 1.2102 - accuracy: 0.5434 - val_loss: 1.0590 - val_accuracy: 0.6013 - lr: 5.0000e-04\n",
            "Epoch 42/60\n",
            "504/504 [==============================] - 18s 36ms/step - loss: 1.2047 - accuracy: 0.5471 - val_loss: 1.0655 - val_accuracy: 0.5979 - lr: 5.0000e-04\n",
            "Epoch 43/60\n",
            "504/504 [==============================] - 17s 33ms/step - loss: 1.2036 - accuracy: 0.5490 - val_loss: 1.0549 - val_accuracy: 0.5974 - lr: 5.0000e-04\n",
            "Epoch 44/60\n",
            "504/504 [==============================] - 18s 35ms/step - loss: 1.2035 - accuracy: 0.5467 - val_loss: 1.0560 - val_accuracy: 0.5946 - lr: 5.0000e-04\n",
            "Epoch 45/60\n",
            "504/504 [==============================] - 17s 34ms/step - loss: 1.1985 - accuracy: 0.5477 - val_loss: 1.0532 - val_accuracy: 0.5993 - lr: 5.0000e-04\n",
            "Epoch 46/60\n",
            "504/504 [==============================] - 17s 34ms/step - loss: 1.1961 - accuracy: 0.5511 - val_loss: 1.0568 - val_accuracy: 0.6013 - lr: 5.0000e-04\n",
            "Epoch 47/60\n",
            "504/504 [==============================] - 17s 34ms/step - loss: 1.1931 - accuracy: 0.5520 - val_loss: 1.0550 - val_accuracy: 0.5957 - lr: 5.0000e-04\n",
            "Epoch 48/60\n",
            "504/504 [==============================] - 18s 36ms/step - loss: 1.1928 - accuracy: 0.5507 - val_loss: 1.0585 - val_accuracy: 0.6016 - lr: 5.0000e-04\n",
            "Epoch 49/60\n",
            "504/504 [==============================] - 18s 35ms/step - loss: 1.1903 - accuracy: 0.5525 - val_loss: 1.0519 - val_accuracy: 0.5949 - lr: 5.0000e-04\n",
            "Epoch 50/60\n",
            "504/504 [==============================] - 19s 37ms/step - loss: 1.1898 - accuracy: 0.5522 - val_loss: 1.0585 - val_accuracy: 0.5971 - lr: 5.0000e-04\n",
            "Epoch 51/60\n",
            "504/504 [==============================] - 17s 34ms/step - loss: 1.1874 - accuracy: 0.5517 - val_loss: 1.0512 - val_accuracy: 0.5940 - lr: 5.0000e-04\n",
            "Epoch 52/60\n",
            "504/504 [==============================] - 18s 36ms/step - loss: 1.1884 - accuracy: 0.5531 - val_loss: 1.0555 - val_accuracy: 0.5954 - lr: 5.0000e-04\n",
            "Epoch 53/60\n",
            "504/504 [==============================] - 17s 34ms/step - loss: 1.1862 - accuracy: 0.5536 - val_loss: 1.0423 - val_accuracy: 0.6024 - lr: 5.0000e-04\n",
            "Epoch 54/60\n",
            "504/504 [==============================] - 17s 34ms/step - loss: 1.1869 - accuracy: 0.5568 - val_loss: 1.0461 - val_accuracy: 0.5979 - lr: 5.0000e-04\n",
            "Epoch 55/60\n",
            "504/504 [==============================] - 19s 37ms/step - loss: 1.1798 - accuracy: 0.5588 - val_loss: 1.0487 - val_accuracy: 0.5979 - lr: 5.0000e-04\n",
            "Epoch 56/60\n",
            "504/504 [==============================] - 17s 34ms/step - loss: 1.1760 - accuracy: 0.5581 - val_loss: 1.0628 - val_accuracy: 0.5865 - lr: 5.0000e-04\n",
            "Epoch 57/60\n",
            "504/504 [==============================] - 17s 34ms/step - loss: 1.1868 - accuracy: 0.5541 - val_loss: 1.0558 - val_accuracy: 0.5907 - lr: 5.0000e-04\n",
            "Epoch 58/60\n",
            "504/504 [==============================] - 17s 34ms/step - loss: 1.1779 - accuracy: 0.5567 - val_loss: 1.0404 - val_accuracy: 0.6038 - lr: 5.0000e-04\n",
            "Epoch 59/60\n",
            "504/504 [==============================] - 18s 35ms/step - loss: 1.1802 - accuracy: 0.5566 - val_loss: 1.0416 - val_accuracy: 0.5954 - lr: 5.0000e-04\n",
            "Epoch 60/60\n",
            "504/504 [==============================] - 17s 34ms/step - loss: 1.1728 - accuracy: 0.5617 - val_loss: 1.0607 - val_accuracy: 0.5871 - lr: 5.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "print(f'Test Accuracy: {accuracy}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5L2N3jKQMtK",
        "outputId": "2229e63b-16e4-4eb6-b0d3-2893d6051d24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "113/113 [==============================] - 1s 6ms/step - loss: 1.0607 - accuracy: 0.5871\n",
            "Test Loss: 1.0607237815856934\n",
            "Test Accuracy: 0.5870715975761414\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get the model's predictions for the test set\n",
        "y_pred = model.predict(X_test)\n",
        "# Convert predictions to class labels\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "# Convert true labels to class labels\n",
        "y_true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Generate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 735
        },
        "id": "vM8iac72VJRC",
        "outputId": "65167042-101e-4e08-c304-f4544b7a9235"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "113/113 [==============================] - 1s 4ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y_true_classes, y_pred_classes)\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAZMvhAWVg_a",
        "outputId": "8a34bdd9-af30-4ccd-b131-f4ca48767b99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.51      0.49       498\n",
            "           1       0.58      0.13      0.22        52\n",
            "           2       0.43      0.29      0.35       545\n",
            "           3       0.83      0.83      0.83       881\n",
            "           4       0.48      0.42      0.44       588\n",
            "           5       0.70      0.65      0.68       414\n",
            "           6       0.50      0.72      0.59       611\n",
            "\n",
            "    accuracy                           0.59      3589\n",
            "   macro avg       0.57      0.51      0.51      3589\n",
            "weighted avg       0.59      0.59      0.58      3589\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RP1624DFVrbJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}